{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Disease Detection Model Training\n",
    "## EfficientNetB0 Transfer Learning for PlantVillage Dataset\n",
    "\n",
    "This notebook trains a plant disease detection model using transfer learning with EfficientNetB0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../backend')\n",
    "from disease_model import PlantDiseaseModel\n",
    "from utils.preprocessing import create_data_generators, split_dataset\n",
    "from utils.evaluation import ModelEvaluator\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "DATASET_PATH = 'data/PlantVillage'  # Update this path\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = (224, 224)\n",
    "EPOCHS_INITIAL = 10\n",
    "EPOCHS_FINE_TUNE = 15\n",
    "\n",
    "# Create train/val/test splits if they don't exist\n",
    "if not os.path.exists(f\"{DATASET_PATH}_train\"):\n",
    "    print(\"Splitting dataset into train/val/test...\")\n",
    "    split_dataset(DATASET_PATH, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "    print(\"Dataset split completed!\")\n",
    "else:\n",
    "    print(\"Dataset splits already exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators\n",
    "train_generator, val_generator, test_generator = create_data_generators(\n",
    "    train_dir=f\"{DATASET_PATH}_train\",\n",
    "    val_dir=f\"{DATASET_PATH}_val\",\n",
    "    test_dir=f\"{DATASET_PATH}_test\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_size=IMAGE_SIZE\n",
    ")\n",
    "\n",
    "# Get class information\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")\n",
    "print(f\"Class names: {class_names[:5]}...\")  # Show first 5 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = PlantDiseaseModel(num_classes=num_classes, input_shape=(*IMAGE_SIZE, 3))\n",
    "\n",
    "# Build and compile the model\n",
    "model.build_model()\n",
    "model.compile_model(learning_rate=0.001)\n",
    "\n",
    "# Display model summary\n",
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Training (Frozen Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train initial model with frozen base\n",
    "print(\"Starting initial training with frozen EfficientNetB0 base...\")\n",
    "\n",
    "initial_history = model.train_initial(\n",
    "    train_data=train_generator,\n",
    "    val_data=val_generator,\n",
    "    epochs=EPOCHS_INITIAL\n",
    ")\n",
    "\n",
    "print(\"Initial training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot initial training history\n",
    "model.plot_training_history()\n",
    "plt.suptitle('Initial Training (Frozen Base)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "print(\"Starting fine-tuning...\")\n",
    "\n",
    "fine_tune_history = model.fine_tune(\n",
    "    train_data=train_generator,\n",
    "    val_data=val_generator,\n",
    "    epochs=EPOCHS_FINE_TUNE,\n",
    "    unfreeze_layers=50  # Unfreeze top 50 layers\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot combined training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Initial training\n",
    "axes[0, 0].plot(initial_history.history['accuracy'], label='Training')\n",
    "axes[0, 0].plot(initial_history.history['val_accuracy'], label='Validation')\n",
    "axes[0, 0].set_title('Initial Training - Accuracy')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "axes[0, 1].plot(initial_history.history['loss'], label='Training')\n",
    "axes[0, 1].plot(initial_history.history['val_loss'], label='Validation')\n",
    "axes[0, 1].set_title('Initial Training - Loss')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Fine-tuning\n",
    "axes[1, 0].plot(fine_tune_history.history['accuracy'], label='Training')\n",
    "axes[1, 0].plot(fine_tune_history.history['val_accuracy'], label='Validation')\n",
    "axes[1, 0].set_title('Fine-Tuning - Accuracy')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "axes[1, 1].plot(fine_tune_history.history['loss'], label='Training')\n",
    "axes[1, 1].plot(fine_tune_history.history['val_loss'], label='Validation')\n",
    "axes[1, 1].set_title('Fine-Tuning - Loss')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "\n",
    "evaluator = ModelEvaluator(class_names)\n",
    "report, cm = model.evaluate_model(test_generator, class_names)\n",
    "\n",
    "print(f\"Test Accuracy: {report['accuracy']:.4f}\")\n",
    "print(f\"Test Precision: {report['weighted avg']['precision']:.4f}\")\n",
    "print(f\"Test Recall: {report['weighted avg']['recall']:.4f}\")\n",
    "print(f\"Test F1-Score: {report['weighted avg']['f1-score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix (for top 20 classes)\n",
    "top_classes = 20\n",
    "if num_classes > top_classes:\n",
    "    cm_subset = cm[:top_classes, :top_classes]\n",
    "    class_names_subset = class_names[:top_classes]\n",
    "else:\n",
    "    cm_subset = cm\n",
    "    class_names_subset = class_names\n",
    "\n",
    "evaluator_subset = ModelEvaluator(class_names_subset)\n",
    "plt.figure(figsize=(15, 12))\n",
    "evaluator_subset.plot_confusion_matrix(cm_subset, 'Confusion Matrix (Top 20 Classes)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot classification report\n",
    "evaluator.plot_classification_report(report, 'Classification Report')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Saving and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save_model('plant_disease_model.h5')\n",
    "\n",
    "# Convert to TensorFlow Lite\n",
    "tflite_path = model.convert_to_tflite()\n",
    "\n",
    "# Save class names\n",
    "with open('class_names.json', 'w') as f:\n",
    "    json.dump(class_names, f, indent=2)\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "print(f\"Keras model: plant_disease_model.h5\")\n",
    "print(f\"TFLite model: {tflite_path}\")\n",
    "print(f\"Class names: class_names.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Testing with Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with some sample images\n",
    "import cv2\n",
    "from utils.preprocessing import ImagePreprocessor\n",
    "\n",
    "preprocessor = ImagePreprocessor()\n",
    "\n",
    "# Get a batch of test images\n",
    "test_batch = test_generator.next()\n",
    "test_images, test_labels = test_batch\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.model.predict(test_images)\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(8):\n",
    "    # Display image\n",
    "    axes[i].imshow(test_images[i])\n",
    "    \n",
    "    # Get predictions\n",
    "    true_class_idx = np.argmax(test_labels[i])\n",
    "    pred_class_idx = np.argmax(predictions[i])\n",
    "    confidence = predictions[i][pred_class_idx]\n",
    "    \n",
    "    true_class = class_names[true_class_idx]\n",
    "    pred_class = class_names[pred_class_idx]\n",
    "    \n",
    "    # Set title\n",
    "    color = 'green' if true_class_idx == pred_class_idx else 'red'\n",
    "    axes[i].set_title(f'True: {true_class[:15]}...\\nPred: {pred_class[:15]}... ({confidence:.2f})', \n",
    "                     color=color, fontsize=8)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze per-class performance\n",
    "per_class_metrics = evaluator.calculate_per_class_metrics(\n",
    "    np.concatenate([test_generator.next()[1] for _ in range(len(test_generator))]),\n",
    "    predictions\n",
    ")\n",
    "\n",
    "# Create performance DataFrame\n",
    "performance_df = pd.DataFrame(per_class_metrics).T\n",
    "performance_df = performance_df.sort_values('f1_score', ascending=False)\n",
    "\n",
    "print(\"Top 10 Best Performing Classes:\")\n",
    "print(performance_df.head(10)[['precision', 'recall', 'f1_score']])\n",
    "\n",
    "print(\"\\nTop 10 Worst Performing Classes:\")\n",
    "print(performance_df.tail(10)[['precision', 'recall', 'f1_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['precision', 'recall', 'f1_score']\n",
    "for i, metric in enumerate(metrics):\n",
    "    axes[i].hist(performance_df[metric], bins=20, alpha=0.7, edgecolor='black')\n",
    "    axes[i].set_title(f'{metric.title()} Distribution')\n",
    "    axes[i].set_xlabel(metric.title())\n",
    "    axes[i].set_ylabel('Number of Classes')\n",
    "    axes[i].axvline(performance_df[metric].mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {performance_df[metric].mean():.3f}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Size and Inference Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "# Model size comparison\n",
    "keras_size = os.path.getsize('plant_disease_model.h5') / (1024 * 1024)  # MB\n",
    "tflite_size = os.path.getsize(tflite_path) / (1024 * 1024)  # MB\n",
    "\n",
    "print(f\"Keras model size: {keras_size:.2f} MB\")\n",
    "print(f\"TFLite model size: {tflite_size:.2f} MB\")\n",
    "print(f\"Size reduction: {((keras_size - tflite_size) / keras_size * 100):.1f}%\")\n",
    "\n",
    "# Inference speed test\n",
    "test_image = test_images[:1]  # Single image\n",
    "\n",
    "# Keras model speed\n",
    "start_time = time.time()\n",
    "for _ in range(100):\n",
    "    _ = model.model.predict(test_image, verbose=0)\n",
    "keras_time = (time.time() - start_time) / 100\n",
    "\n",
    "# TFLite model speed\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(100):\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "    interpreter.invoke()\n",
    "    _ = interpreter.get_tensor(output_details[0]['index'])\n",
    "tflite_time = (time.time() - start_time) / 100\n",
    "\n",
    "print(f\"\\nInference Speed (average of 100 runs):\")\n",
    "print(f\"Keras model: {keras_time*1000:.2f} ms\")\n",
    "print(f\"TFLite model: {tflite_time*1000:.2f} ms\")\n",
    "print(f\"Speed improvement: {(keras_time/tflite_time):.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final report\n",
    "final_report = f\"\"\"\n",
    "# Plant Disease Detection Model Training Summary\n",
    "\n",
    "## Dataset Information\n",
    "- Total Classes: {num_classes}\n",
    "- Training Samples: {train_generator.samples}\n",
    "- Validation Samples: {val_generator.samples}\n",
    "- Test Samples: {test_generator.samples}\n",
    "\n",
    "## Model Architecture\n",
    "- Base Model: EfficientNetB0 (ImageNet pretrained)\n",
    "- Input Size: {IMAGE_SIZE}\n",
    "- Total Parameters: {model.model.count_params():,}\n",
    "\n",
    "## Training Configuration\n",
    "- Initial Training Epochs: {EPOCHS_INITIAL}\n",
    "- Fine-tuning Epochs: {EPOCHS_FINE_TUNE}\n",
    "- Batch Size: {BATCH_SIZE}\n",
    "- Total Training Epochs: {EPOCHS_INITIAL + EPOCHS_FINE_TUNE}\n",
    "\n",
    "## Final Performance\n",
    "- Test Accuracy: {report['accuracy']:.4f}\n",
    "- Test Precision: {report['weighted avg']['precision']:.4f}\n",
    "- Test Recall: {report['weighted avg']['recall']:.4f}\n",
    "- Test F1-Score: {report['weighted avg']['f1-score']:.4f}\n",
    "\n",
    "## Model Optimization\n",
    "- Keras Model Size: {keras_size:.2f} MB\n",
    "- TFLite Model Size: {tflite_size:.2f} MB\n",
    "- Size Reduction: {((keras_size - tflite_size) / keras_size * 100):.1f}%\n",
    "- Inference Speed (TFLite): {tflite_time*1000:.2f} ms\n",
    "\n",
    "## Model Files\n",
    "- Keras Model: plant_disease_model.h5\n",
    "- TFLite Model: {tflite_path}\n",
    "- Class Names: class_names.json\n",
    "\"\"\"\n",
    "\n",
    "print(final_report)\n",
    "\n",
    "# Save report\n",
    "with open('training_report.md', 'w') as f:\n",
    "    f.write(final_report)\n",
    "\n",
    "print(\"\\n✅ Training completed successfully!\")\n",
    "print(\"📊 All results and models have been saved.\")\n",
    "print(\"🚀 Ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}